{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing_extensions import DefaultDict\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, precision_score, recall_score,  classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from scipy.stats import randint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando os conjuntos da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_path = \"../test_normalized.csv\"\n",
    "val_path = \"../val_normalized.csv\"\n",
    "subtrain_path = \"../train_normalized.csv\"\n",
    "\n",
    "df_val = pd.read_csv(val_path, index_col=0)\n",
    "df_test = pd.read_csv(test_path, index_col=0)\n",
    "df_subtrain = pd.read_csv(subtrain_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Validação:\", df_val.shape)\n",
    "print(\"Teste:\", df_test.shape)\n",
    "print(\"Sub-conjunto de treinamento\", df_subtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Separando as variáveis independentes (X) e dependentes (y) para o subtrain\n",
    "X_train_subset = df_subtrain.iloc[:, :-1] \n",
    "y_train_subset  = df_subtrain.iloc[:, -1] \n",
    "\n",
    "X_val = df_val.iloc[:, :-1]\n",
    "y_val = df_val.iloc[:, -1]\n",
    "\n",
    "X_test = df_test.iloc[:, :-1]\n",
    "y_test = df_test.iloc[:, -1]\n",
    "\n",
    "# Unificando as variáveis independentes (X) de treino e validação\n",
    "X_train = pd.concat([X_train_subset, X_val], axis=0)\n",
    "\n",
    "# Unificando as variáveis dependentes (y) de treino e validação\n",
    "y_train= pd.concat([y_train_subset, y_val], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Achando os melhores hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "modelo_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': randint(1, 21),  \n",
    "    'min_samples_split': randint(2, 21),  \n",
    "    'min_samples_leaf': randint(1, 21), \n",
    "    'criterion': ['gini', 'entropy'], \n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    modelo_dt, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=20,  # 20 iterações\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),  \n",
    "    n_jobs=-1,  \n",
    "    random_state=42,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_subset, y_train_subset)\n",
    "\n",
    "#Encontrando as médias e desvio-padrão dos resultados\n",
    "results = random_search.cv_results_\n",
    "mean_scores = results['mean_test_score']\n",
    "std_scores = results['std_test_score']\n",
    "\n",
    "melhor_modelo = random_search.best_estimator_\n",
    "\n",
    "# Avaliação no conjunto de validação\n",
    "y_val_pred = melhor_modelo.predict(X_val)\n",
    "acuracia_val = accuracy_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot e resultados da busca de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(range(1, len(mean_scores) + 1), mean_scores, yerr=std_scores, fmt='o', color='b', label='Acurácia média', linestyle='-')\n",
    "plt.xlabel('Iterações')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.title('Evolução do Desempenho nas Iterações do RandomizedSearchCV')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Melhor Acurácia no conjunto de validação: {acuracia_val}\")\n",
    "print(f\"Melhores parâmetros: {random_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento e teste com melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "melhor_modelo.fit(X_train, y_train)\n",
    "\n",
    "# Prevendo os resultados no conjunto de teste\n",
    "y_pred = melhor_modelo.predict(X_test)\n",
    "\n",
    "# Cálculo das métricas de avaliação\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro') \n",
    "recall = recall_score(y_test, y_pred, average='macro')  \n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Acurácia: {accuracy:.4f}\")\n",
    "print(f\"Precisão: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotando a Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Não Aprovado', 'Aprovado'], yticklabels=['Não Aprovado', 'Aprovado'])\n",
    "plt.xlabel('Predição')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
